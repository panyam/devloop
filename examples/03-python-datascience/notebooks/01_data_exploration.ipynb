{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration Notebook\n",
    "\n",
    "This notebook demonstrates exploratory data analysis for our Python Data Science example.\n",
    "\n",
    "When you modify this notebook, devloop will automatically restart Jupyter Lab to reflect your changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, os.path.join('..', 'src'))\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Let's load our processed data and examine its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load processed data, generate if not available\n",
    "try:\n",
    "    customers = pd.read_csv('../data/processed/enriched_customers.csv')\n",
    "    transactions = pd.read_csv('../data/processed/transactions.csv')\n",
    "    print(\"Loaded processed data successfully!\")\nexcept FileNotFoundError:\n",
    "    print(\"Processed data not found. Run the preprocessing pipeline first.\")\n",
    "    print(\"Or generate sample data for exploration...\")\n",
    "    \n",
    "    # Generate sample data for demonstration\n",
    "    from train import generate_synthetic_data\n",
    "    sample_data = generate_synthetic_data()\n",
    "    print(f\"Generated sample data: {sample_data.shape}\")\n",
    "    customers = sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset Shape:\", customers.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(customers.columns.tolist())\n",
    "print(\"\\nData Types:\")\n",
    "print(customers.dtypes)\n",
    "print(\"\\nFirst few rows:\")\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "customers.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_data = customers.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_data[missing_data > 0])\n",
    "\n",
    "if missing_data.sum() == 0:\n",
    "    print(\"✅ No missing values found!\")\nelse:\n",
    "    print(f\"⚠️  Total missing values: {missing_data.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = customers.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "if duplicates == 0:\n",
    "    print(\"✅ No duplicates found!\")\nelse:\n",
    "    print(f\"⚠️  Found {duplicates} duplicate rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization grid\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Data Distribution Analysis', fontsize=16)\n",
    "\n",
    "# Plot distributions for numeric columns\n",
    "numeric_cols = customers.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "for i, col in enumerate(numeric_cols[:4]):  # Plot first 4 numeric columns\n",
    "    row = i // 2\n",
    "    col_idx = i % 2\n",
    "    \n",
    "    axes[row, col_idx].hist(customers[col], bins=30, alpha=0.7, edgecolor='black')\n",
    "    axes[row, col_idx].set_title(f'Distribution of {col}')\n",
    "    axes[row, col_idx].set_xlabel(col)\n",
    "    axes[row, col_idx].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numeric features\n",
    "if len(numeric_cols) > 1:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    correlation_matrix = customers[numeric_cols].corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze target variable if it exists\n",
    "if 'target' in customers.columns:\n",
    "    target_counts = customers['target'].value_counts()\n",
    "    print(\"Target variable distribution:\")\n",
    "    print(target_counts)\n",
    "    print(f\"\\nClass balance: {target_counts.min() / target_counts.max():.3f}\")\n",
    "    \n",
    "    # Plot target distribution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    customers['target'].value_counts().plot(kind='bar')\n",
    "    plt.title('Target Variable Distribution')\n",
    "    plt.xlabel('Target Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.show()\nelse:\n",
    "    print(\"No target variable found in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot for first few numeric features\n",
    "if len(numeric_cols) >= 3:\n",
    "    sample_cols = numeric_cols[:3].tolist()\n",
    "    if 'target' in customers.columns:\n",
    "        sample_cols.append('target')\n",
    "    \n",
    "    # Sample data if too large\n",
    "    sample_size = min(1000, len(customers))\n",
    "    sample_data = customers[sample_cols].sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    if 'target' in sample_cols:\n",
    "        sns.pairplot(sample_data, hue='target', alpha=0.7)\n",
    "    else:\n",
    "        sns.pairplot(sample_data, alpha=0.7)\n",
    "    plt.suptitle('Feature Relationships', y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides a comprehensive overview of our dataset. Key findings:\n",
    "\n",
    "1. **Data Quality**: Checked for missing values and duplicates\n",
    "2. **Distributions**: Analyzed feature distributions\n",
    "3. **Correlations**: Examined relationships between features\n",
    "4. **Target Analysis**: Analyzed target variable distribution\n",
    "\n",
    "Next steps:\n",
    "- Feature engineering based on insights\n",
    "- Model selection and training\n",
    "- Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save analysis results\n",
    "analysis_summary = {\n",
    "    'total_samples': len(customers),\n",
    "    'total_features': len(customers.columns),\n",
    "    'missing_values': customers.isnull().sum().sum(),\n",
    "    'duplicate_rows': customers.duplicated().sum(),\n",
    "}\n",
    "\n",
    "print(\"Analysis Summary:\")\n",
    "for key, value in analysis_summary.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}